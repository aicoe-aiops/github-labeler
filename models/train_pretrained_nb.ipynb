{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4bff5cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/atersaak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import boto3\n",
    "import sys\n",
    "import pandas as pd\n",
    "from model_classes import FtModel, SVM\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "vocab_path = \"../src/data\"\n",
    "if vocab_path not in sys.path:\n",
    "    sys.path.insert(1, vocab_path)\n",
    "\n",
    "from preprocess import preprocess, process\n",
    "from w2v_preprocess import is_punc # noqa\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c52c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = os.getenv(\"REPO_NAME\")\n",
    "\n",
    "if \"/\" in name:\n",
    "    REPO = name\n",
    "    USER = \"\"\n",
    "else:\n",
    "    USER = name\n",
    "    REPO = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9631ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e6d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_ceph = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325ea9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to use ceph or store locally\n",
    "\n",
    "use_ceph = True\n",
    "\n",
    "if use_ceph:\n",
    "    s3_endpoint_url = os.environ[\"OBJECT_STORAGE_ENDPOINT_URL\"]\n",
    "    s3_access_key = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "    s3_secret_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "    s3_bucket = os.environ[\"OBJECT_STORAGE_BUCKET_NAME\"]\n",
    "\n",
    "    s3 = boto3.client(\n",
    "        service_name=\"s3\",\n",
    "        aws_access_key_id=s3_access_key,\n",
    "        aws_secret_access_key=s3_secret_key,\n",
    "        endpoint_url=s3_endpoint_url,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c89c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('github-labeler/w2v/.*')\n",
    "\n",
    "buck = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key,\n",
    "    endpoint_url=s3_endpoint_url,\n",
    ")\n",
    "\n",
    "keys = []\n",
    "\n",
    "for obj in buck.Bucket(s3_bucket).objects.all():\n",
    "    if pattern.match(obj.key):\n",
    "        keys.append(obj.key)\n",
    "\n",
    "keys = [os.path.basename(key) for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2749f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_ceph:\n",
    "    for key in keys:\n",
    "        response = s3.get_object(\n",
    "            Bucket=s3_bucket,\n",
    "            Key=f\"github-labeler/w2v/{key}\",\n",
    "        )\n",
    "        with open(f'../models/{key}' ,'wb') as f:\n",
    "            for i in response['Body']:\n",
    "                f.write(i)\n",
    "\n",
    "w = Word2Vec.load('../models/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65dfc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = w.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dfc23ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.23742183e-01,  2.32883527e-01,  2.37421694e-01,  1.72353471e-01,\n",
       "       -2.18682564e-01,  1.82947338e-01, -2.46382981e-01,  1.44234826e-01,\n",
       "       -2.99687221e-02,  4.11167992e-01, -8.03297702e-02, -1.31971191e-01,\n",
       "        1.72190587e-01,  1.18970575e-01, -1.10150887e-01,  3.69050753e-01,\n",
       "        3.36970819e-01,  3.11997259e-01,  3.05851019e-01,  2.47959185e-01,\n",
       "        5.52929727e-02,  2.80811273e-04,  1.24124149e-01, -2.01001166e-01,\n",
       "       -1.70063632e-02, -6.75225474e-02, -4.99156970e-02,  8.20819799e-02,\n",
       "       -7.90059572e-02,  1.39661219e-01,  4.87351409e-01,  1.42484934e-01,\n",
       "        1.62602014e-02, -3.32129484e-01,  2.60693022e-02, -6.16326118e-02,\n",
       "       -3.24902504e-01,  9.79855351e-02, -9.46882363e-02,  7.94708150e-03,\n",
       "        7.16395413e-02,  6.90607377e-02,  8.12420606e-02,  3.74224111e-02,\n",
       "       -2.58287327e-02, -1.12986857e-01,  2.76075428e-01, -2.21995813e-01,\n",
       "       -1.74412349e-01,  1.83697060e-01, -1.00397553e-01,  3.63611964e-01,\n",
       "        1.79405002e-01,  4.15600123e-02,  1.67544118e-01, -9.19931420e-02,\n",
       "        2.27941543e-01, -2.92082977e-02, -3.62555416e-02,  2.40558725e-01,\n",
       "        3.25645383e-03,  1.25377879e-01, -3.26567102e-01,  7.06435993e-02,\n",
       "       -1.36529461e-02, -2.47947635e-01, -2.63005062e-01,  2.19967814e-01,\n",
       "       -9.07690203e-02, -1.30449812e-01,  8.02527142e-02,  1.10638195e-01,\n",
       "       -4.96928793e-02, -1.11432472e-01,  4.84628974e-02, -4.03220023e-02,\n",
       "       -1.67137865e-01,  1.37188284e-01,  9.26241606e-02, -3.91538673e-02,\n",
       "       -4.94309795e-02, -1.12330243e-02, -3.01788817e-02, -1.02874413e-01,\n",
       "       -6.53115070e-02, -2.74593648e-02, -1.71434721e-01,  4.68027735e-02,\n",
       "        6.94804899e-02,  2.82300448e-02,  2.46313576e-01, -2.31638619e-04,\n",
       "        1.93007781e-01, -1.62703684e-02,  2.56003480e-01, -1.37242264e-01,\n",
       "        6.66828287e-02,  1.74703717e-01,  1.02364374e-01, -4.94151767e-02,\n",
       "        9.04554194e-02, -1.34279210e-02,  1.32519948e-01, -1.61735586e-01,\n",
       "        2.45080600e-01,  1.06982614e-01,  2.63676538e-02,  1.12068488e-01,\n",
       "        1.56574359e-02,  4.61487283e-03, -2.86735513e-03, -5.01358437e-02,\n",
       "       -5.54072355e-02,  8.24612511e-02,  5.09742038e-02, -2.32526018e-02,\n",
       "       -3.92538993e-02, -5.88987700e-03, -4.63139638e-02,  1.28072329e-02,\n",
       "        1.59993226e-01, -8.00586803e-02, -6.58459816e-02, -3.19798904e-01,\n",
       "       -8.34381829e-02,  2.38829684e-02,  2.23474816e-02, -6.42287558e-02,\n",
       "       -7.69812981e-02, -4.77012595e-03,  1.46400302e-01,  1.49188019e-01,\n",
       "       -2.50475795e-01, -3.27529221e-01,  2.81585181e-02, -5.76029714e-02,\n",
       "       -3.73345308e-02,  5.68469844e-02,  5.65992558e-02, -1.50791247e-02,\n",
       "        1.83783627e-01,  1.21224660e-01, -5.32394941e-02,  1.31199076e-01,\n",
       "        1.41130360e-02, -5.00822269e-02,  8.34683338e-02,  1.66901217e-02,\n",
       "        4.27547857e-02, -1.13323182e-01,  7.52018066e-02, -1.83791673e-01,\n",
       "        4.56408955e-02,  6.70958058e-02, -2.08200273e-01, -2.07861454e-02,\n",
       "        6.73370757e-02, -7.23431263e-02, -6.65967260e-02, -4.42558052e-02,\n",
       "        1.39128295e-01, -1.34551553e-01,  1.13939484e-02,  2.37632631e-02,\n",
       "       -1.47020342e-01, -2.19596678e-02,  7.46591498e-02,  1.27648408e-01,\n",
       "       -7.18978096e-02, -2.54113708e-02, -3.10452535e-02,  1.02217901e-01,\n",
       "       -1.10327368e-01, -7.15899469e-03, -3.98884929e-03])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['slime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25b96339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bee5e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = w.wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a22c8018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486641e3d33d44a2a852015195fb14ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/386705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_vocab = w.wv.vocab\n",
    "\n",
    "with open('vocab.vec', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(str(len(full_vocab)) + ' ' + str(vec_size) + '\\n')\n",
    "    for word in tqdm(full_vocab):\n",
    "        vector = w.wv[word]\n",
    "        vector = [str(v) for v in vector]\n",
    "        f.write(word + ' ' + ' '.join(vector))\n",
    "        f.write('\\n')\n",
    "\n",
    "full_vocab = set(full_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a9a41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skift import FirstColFtClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b891624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_set(word):\n",
    "    \"\"\"Check if the word is in our set.\"\"\"\n",
    "    if word in full_vocab:\n",
    "        return word\n",
    "    else:\n",
    "        return '_unknown_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9ad4435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FtModel_Pretrained(FirstColFtClassifier):\n",
    "    \"\"\"This model is written over the skift column first classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, path=\"\"):\n",
    "        \"\"\"Initialize the model.\"\"\"\n",
    "        if not path:\n",
    "            super().__init__(pretrainedVectors = 'vocab.vec', dim = vec_size)\n",
    "        else:\n",
    "            model = fasttext.load_model(path)\n",
    "            setattr(self, \"model\", model)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        \"\"\"Preprocess the text from a dataframe with processed column.\"\"\"\n",
    "        ret = x.title.fillna('') + ' SEP ' + x.body.fillna('')\n",
    "        ret = ret.apply(preprocess)\n",
    "        ret = ret.apply(lambda x: x.lower())\n",
    "        ret = ret.apply(word_tokenize).values\n",
    "        ret = [[word for word in issue if not is_punc(word)] for issue in ret]\n",
    "        ret = [[in_set(w) for w in issue] for issue in ret]\n",
    "        ret = [' '.join(issue) for issue in ret]\n",
    "        return ret\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Fit the model.\"\"\"\n",
    "        input_ = np.array(self.preprocess(x)).reshape(-1, 1)\n",
    "        super().fit(input_, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict the output.\"\"\"\n",
    "        input_ = self.preprocess(x)\n",
    "        return super().predict(input_)\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Save the model.\"\"\"\n",
    "        return self.model.save_model(path)\n",
    "\n",
    "    def inference(self, title, body):\n",
    "        \"\"\"Inference for the app.\"\"\"\n",
    "        input_ = np.array(process(title, body)).reshape(1, -1)\n",
    "        pred = super().predict(input_)\n",
    "        return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f244879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = USER if USER else REPO.replace(\"/\", \"-_-\")\n",
    "path = os.path.join(\"../data\", savename + \".csv\")\n",
    "key = f\"github-labeler/data/{savename}.csv\"\n",
    "\n",
    "if use_ceph:\n",
    "    response = s3.get_object(Bucket=s3_bucket, Key=key)\n",
    "    issues_df = pd.read_csv(response.get(\"Body\")).drop_duplicates()\n",
    "else:\n",
    "    issues_df = pd.read_csv(path).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "acb5366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = issues_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "379546d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdataset(label):\n",
    "    \"\"\"\n",
    "    pass in a label name and get back a dataframe of positive & negative samples for the label\n",
    "    we avoid taking unlabelled data as negative samples\n",
    "    negative samples are distributed evenly amongst the other labels\n",
    "    \"\"\"\n",
    "    labelled = issues_df[~issues_df.labels.isna()]\n",
    "    final_labels_ = final_labels.copy()\n",
    "    final_labels_.remove(label)\n",
    "    pos_samples = labelled[labelled.labels.apply(lambda x: label in x.split(\"\\t\"))]\n",
    "    n = len(pos_samples)\n",
    "    remaining = labelled[labelled.id.apply(lambda x: label not in x.split(\"\\t\"))]\n",
    "    n_neg = 0\n",
    "    per_label = n // len(final_labels_)\n",
    "    neg_ids = set()\n",
    "    # evenly sample if we can\n",
    "    # if not enough samples for a label, throw them all in and increase the remaining amount we need per label\n",
    "    for i, lbl in enumerate(reversed(final_labels_)):\n",
    "        neg_samples = remaining[remaining.labels.apply(lambda x: lbl in x.split(\"\\t\"))]\n",
    "        if len(neg_samples) >= per_label:\n",
    "            neg_samples = neg_samples.sample(per_label)\n",
    "            n_neg += per_label\n",
    "        else:\n",
    "            n_neg += len(neg_samples)\n",
    "            if i != len(final_labels_) - 1:\n",
    "                per_label = (n - n_neg) // (len(final_labels_) - i - 1)\n",
    "        remaining = remaining[\n",
    "            remaining.labels.apply(lambda x: lbl not in x.split(\"\\t\"))\n",
    "        ]\n",
    "        neg_ids = neg_ids.union(set(neg_samples.id))\n",
    "    # fill in potential gap with unlabelled issues, if needed\n",
    "    if len(pos_samples) > len(neg_ids):\n",
    "        unlabelled = issues_df.query(\"num_labels == 0\")\n",
    "        if len(unlabelled) > len(pos_samples) - len(neg_ids):\n",
    "            neg_ids = neg_ids.union(\n",
    "                set(unlabelled.sample(len(pos_samples) - len(neg_ids)).id)\n",
    "            )\n",
    "        else:\n",
    "            neg_ids = neg_ids.union(set(unlabelled.id))\n",
    "            pos_samples = pos_samples.sample(len(neg_ids))\n",
    "    final_neg_samples = issues_df[issues_df.id.apply(lambda x: x in neg_ids)]\n",
    "    x = pd.concat((final_neg_samples, pos_samples))\n",
    "    y = np.concatenate((np.zeros(len(final_neg_samples)), np.ones(len(pos_samples))))\n",
    "    return x, y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d38ec92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(label, k=5, model_class=FtModel):\n",
    "    \"\"\"\n",
    "    validates fastText model on the given label, using k-fold cross validation\n",
    "    \"\"\"\n",
    "    x, y = get_subdataset(label)\n",
    "    kf = KFold(n_splits=k, random_state=None, shuffle=True)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        model = model_class()\n",
    "        x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        preds = model.predict(x_test)\n",
    "        accuracy.append(np.mean(preds == y_test))\n",
    "        precision_ = preds[preds == 1] == y_test[preds == 1]\n",
    "        if len(precision_) != 0:\n",
    "            precision.append(np.mean(precision_))\n",
    "        recall_ = preds[y_test == 1] == y_test[y_test == 1]\n",
    "        if len(recall_) != 0:\n",
    "            recall.append(np.mean(recall_))\n",
    "    cols = [\"label\", \"n\", \"accuracy\", \"precision\", \"recall\"]\n",
    "    data = [label, len(x), np.mean(accuracy), np.mean(precision), np.mean(recall)]\n",
    "    return pd.DataFrame([data], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2eedae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df[\"processed\"] = issues_df.apply(\n",
    "    lambda row: np.array(process(row[\"title\"], row[\"body\"])), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a0ef36c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "FastTextClassifier methods must get a two-dimensional numpy array (or castable) as the X parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skift/core.py\u001b[0m in \u001b[0;36m_validate_x\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 raise ValueError(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-9cded9822407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFtModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFtModel_Pretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ft\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ft_pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-e5b78fa5005b>\u001b[0m in \u001b[0;36mpredict_label\u001b[0;34m(label, k, model_class)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprecision_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-0b7a2143c4a2>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;34m\"\"\"Predict the output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skift/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    165\u001b[0m         return np.array([\n\u001b[1;32m    166\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         ], dtype=np.float_)\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skift/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, k)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# Input validation{\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_on_str_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skift/core.py\u001b[0m in \u001b[0;36m_validate_x\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mFtClassifierABC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skift/core.py\u001b[0m in \u001b[0;36m_validate_x\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m     77\u001b[0m                     \u001b[0;34m\"FastTextClassifier methods must get a two-dimensional \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \"numpy array (or castable) as the X parameter.\")\n",
      "\u001b[0;31mValueError\u001b[0m: FastTextClassifier methods must get a two-dimensional numpy array (or castable) as the X parameter."
     ]
    }
   ],
   "source": [
    "final_labels = ['kind/bug', 'kind/feature']\n",
    "\n",
    "predicted_labels = []\n",
    "for label in final_labels:\n",
    "    pred_1 = predict_label(label, model_class=FtModel)\n",
    "    pred_2 = predict_label(label, model_class=FtModel_Pretrained)\n",
    "    pred_1[\"model\"] = \"ft\"\n",
    "    pred_2[\"model\"] = \"ft_pt\"\n",
    "    predicted_labels.append(pred_1)\n",
    "    predicted_labels.append(pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4a294ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.vec', 'r') as f:\n",
    "    o = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "36a25161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386705"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40daf4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440609435"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(i) for i in o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "03e969d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = FtModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f2262357",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0,0,0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f3616b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "20fde638",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(issues_df.sample(6), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3d413167",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cacba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
