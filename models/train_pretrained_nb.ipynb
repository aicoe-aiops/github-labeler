{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60ff8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/atersaak/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/atersaak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/atersaak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import boto3\n",
    "import sys\n",
    "import pandas as pd\n",
    "from model_classes import FtModel, SVM\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "vocab_path = \"../src/data\"\n",
    "if vocab_path not in sys.path:\n",
    "    sys.path.insert(1, vocab_path)\n",
    "\n",
    "from preprocess import preprocess, process\n",
    "from w2v_preprocess import is_punc # noqa\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f34d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = os.getenv(\"REPO_NAME\")\n",
    "\n",
    "if \"/\" in name:\n",
    "    REPO = name\n",
    "    USER = \"\"\n",
    "else:\n",
    "    USER = name\n",
    "    REPO = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f35cbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4976a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_ceph = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d227afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to use ceph or store locally\n",
    "\n",
    "use_ceph = True\n",
    "\n",
    "if use_ceph:\n",
    "    s3_endpoint_url = os.environ[\"OBJECT_STORAGE_ENDPOINT_URL\"]\n",
    "    s3_access_key = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "    s3_secret_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "    s3_bucket = os.environ[\"OBJECT_STORAGE_BUCKET_NAME\"]\n",
    "\n",
    "    s3 = boto3.client(\n",
    "        service_name=\"s3\",\n",
    "        aws_access_key_id=s3_access_key,\n",
    "        aws_secret_access_key=s3_secret_key,\n",
    "        endpoint_url=s3_endpoint_url,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4123e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('github-labeler/w2v/.*')\n",
    "\n",
    "buck = boto3.resource(\n",
    "    service_name=\"s3\",\n",
    "    aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key,\n",
    "    endpoint_url=s3_endpoint_url,\n",
    ")\n",
    "\n",
    "keys = []\n",
    "\n",
    "for obj in buck.Bucket(s3_bucket).objects.all():\n",
    "    if pattern.match(obj.key):\n",
    "        keys.append(obj.key)\n",
    "\n",
    "keys = [os.path.basename(key) for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b9e184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2b31b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ff38db360946d9ad62811e665ef275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68837222225c4c6f8ea651c9d8487b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7be799c2744a31b80a7639e025095b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9877e374db4cda832a7728e2cc8e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if use_ceph:\n",
    "    for key in keys:\n",
    "        response = s3.get_object(\n",
    "            Bucket=s3_bucket,\n",
    "            Key=f\"github-labeler/w2v/{key}\",\n",
    "        )\n",
    "        with open(f'../models/{key}' ,'wb') as f:\n",
    "            for i in tqdm(response['Body']):\n",
    "                f.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efe13e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word2Vec.load('../models/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6bae563",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = w.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99cd1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e3ca3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = w.wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d548c6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07aa96a938b044369983ce962bfb25fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/386705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_vocab = w.wv.index_to_key\n",
    "\n",
    "with open('vocab.vec', 'w', encoding = 'utf-8') as f:\n",
    "    f.write(str(len(full_vocab)) + ' ' + str(vec_size) + '\\n')\n",
    "    for word in tqdm(full_vocab):\n",
    "        vector = w.wv[word]\n",
    "        vector = [str(v) for v in vector]\n",
    "        f.write(word + ' ' + ' '.join(vector))\n",
    "        f.write('\\n')\n",
    "\n",
    "full_vocab = set(full_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63333cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skift import FirstColFtClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7384e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_set(word):\n",
    "    \"\"\"Check if the word is in our set.\"\"\"\n",
    "    if word in full_vocab:\n",
    "        return word\n",
    "    else:\n",
    "        return '_unknown_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0a44252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FtModel_Pretrained(FirstColFtClassifier):\n",
    "    \"\"\"This model is written over the skift column first classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, path=\"\"):\n",
    "        \"\"\"Initialize the model.\"\"\"\n",
    "        if not path:\n",
    "            super().__init__(pretrainedVectors = 'vocab.vec', dim = vec_size)\n",
    "        else:\n",
    "            model = fasttext.load_model(path)\n",
    "            setattr(self, \"model\", model)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        \"\"\"Preprocess the text from a dataframe with processed column.\"\"\"\n",
    "        ret = x.title.fillna('') + ' SEP ' + x.body.fillna('')\n",
    "        ret = ret.apply(preprocess)\n",
    "        ret = ret.apply(lambda x: x.lower())\n",
    "        ret = ret.apply(word_tokenize).values\n",
    "        ret = [[word for word in issue if not is_punc(word)] for issue in ret]\n",
    "        ret = [[in_set(w) for w in issue] for issue in ret]\n",
    "        ret = [' '.join(issue) for issue in ret]\n",
    "        return ret\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Fit the model.\"\"\"\n",
    "        input_ = np.array(self.preprocess(x)).reshape(-1, 1)\n",
    "        super().fit(input_, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict the output.\"\"\"\n",
    "        input_ = np.array(self.preprocess(x)).reshape(-1, 1)\n",
    "        return super().predict(input_)\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Save the model.\"\"\"\n",
    "        return self.model.save_model(path)\n",
    "\n",
    "    def inference(self, title, body):\n",
    "        \"\"\"Inference for the app.\"\"\"\n",
    "        input_ = np.array(process(title, body)).reshape(1, -1)\n",
    "        pred = super().predict(input_)\n",
    "        return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72379187",
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = USER if USER else REPO.replace(\"/\", \"-_-\")\n",
    "path = os.path.join(\"../data\", savename + \".csv\")\n",
    "key = f\"github-labeler/data/{savename}.csv\"\n",
    "\n",
    "if use_ceph:\n",
    "    response = s3.get_object(Bucket=s3_bucket, Key=key)\n",
    "    issues_df = pd.read_csv(response.get(\"Body\")).drop_duplicates()\n",
    "else:\n",
    "    issues_df = pd.read_csv(path).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "730f0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdataset(label):\n",
    "    \"\"\"\n",
    "    pass in a label name and get back a dataframe of positive & negative samples for the label\n",
    "    we avoid taking unlabelled data as negative samples\n",
    "    negative samples are distributed evenly amongst the other labels\n",
    "    \"\"\"\n",
    "    labelled = issues_df[~issues_df.labels.isna()]\n",
    "    final_labels_ = final_labels.copy()\n",
    "    final_labels_.remove(label)\n",
    "    pos_samples = labelled[labelled.labels.apply(lambda x: label in x.split(\"\\t\"))]\n",
    "    n = len(pos_samples)\n",
    "    remaining = labelled[labelled.id.apply(lambda x: label not in x.split(\"\\t\"))]\n",
    "    n_neg = 0\n",
    "    per_label = n // len(final_labels_)\n",
    "    neg_ids = set()\n",
    "    # evenly sample if we can\n",
    "    # if not enough samples for a label, throw them all in and increase the remaining amount we need per label\n",
    "    for i, lbl in enumerate(reversed(final_labels_)):\n",
    "        neg_samples = remaining[remaining.labels.apply(lambda x: lbl in x.split(\"\\t\"))]\n",
    "        if len(neg_samples) >= per_label:\n",
    "            neg_samples = neg_samples.sample(per_label)\n",
    "            n_neg += per_label\n",
    "        else:\n",
    "            n_neg += len(neg_samples)\n",
    "            if i != len(final_labels_) - 1:\n",
    "                per_label = (n - n_neg) // (len(final_labels_) - i - 1)\n",
    "        remaining = remaining[\n",
    "            remaining.labels.apply(lambda x: lbl not in x.split(\"\\t\"))\n",
    "        ]\n",
    "        neg_ids = neg_ids.union(set(neg_samples.id))\n",
    "    # fill in potential gap with unlabelled issues, if needed\n",
    "    if len(pos_samples) > len(neg_ids):\n",
    "        unlabelled = issues_df.query(\"num_labels == 0\")\n",
    "        if len(unlabelled) > len(pos_samples) - len(neg_ids):\n",
    "            neg_ids = neg_ids.union(\n",
    "                set(unlabelled.sample(len(pos_samples) - len(neg_ids)).id)\n",
    "            )\n",
    "        else:\n",
    "            neg_ids = neg_ids.union(set(unlabelled.id))\n",
    "            pos_samples = pos_samples.sample(len(neg_ids))\n",
    "    final_neg_samples = issues_df[issues_df.id.apply(lambda x: x in neg_ids)]\n",
    "    x = pd.concat((final_neg_samples, pos_samples))\n",
    "    y = np.concatenate((np.zeros(len(final_neg_samples)), np.ones(len(pos_samples))))\n",
    "    return x, y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb0dea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5eee368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(label, k=5, model_class=FtModel):\n",
    "    \"\"\"\n",
    "    validates fastText model on the given label, using k-fold cross validation\n",
    "    \"\"\"\n",
    "    x, y = get_subdataset(label)\n",
    "    kf = KFold(n_splits=k, random_state=None, shuffle=True)\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "#     for train_index, test_index in kf.split(x):\n",
    "#         model = model_class()\n",
    "#         x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    model = model_class()\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    accuracy.append(np.mean(preds == y_test))\n",
    "    precision_ = preds[preds == 1] == y_test[preds == 1]\n",
    "    if len(precision_) != 0:\n",
    "        precision.append(np.mean(precision_))\n",
    "    recall_ = preds[y_test == 1] == y_test[y_test == 1]\n",
    "    if len(recall_) != 0:\n",
    "        recall.append(np.mean(recall_))\n",
    "    cols = [\"label\", \"n\", \"accuracy\", \"precision\", \"recall\"]\n",
    "    data = [label, len(x), np.mean(accuracy), np.mean(precision), np.mean(recall)]\n",
    "    return pd.DataFrame([data], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69fda195",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df[\"processed\"] = issues_df.apply(\n",
    "    lambda row: np.array(process(row[\"title\"], row[\"body\"])), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44901be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = ['kind/bug', 'kind/feature', 'kind/test-flake', 'component/cli', 'kind/question']\n",
    "\n",
    "predicted_labels = []\n",
    "for label in final_labels:\n",
    "    pred_1 = predict_label(label, model_class=FtModel)\n",
    "    pred_2 = predict_label(label, model_class=FtModel_Pretrained)\n",
    "    pred_1[\"model\"] = \"ft\"\n",
    "    pred_2[\"model\"] = \"ft_pt\"\n",
    "    predicted_labels.append(pred_1)\n",
    "    predicted_labels.append(pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee249fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kind/bug</td>\n",
       "      <td>3736</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.713528</td>\n",
       "      <td>0.698701</td>\n",
       "      <td>ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kind/bug</td>\n",
       "      <td>3736</td>\n",
       "      <td>0.675134</td>\n",
       "      <td>0.675258</td>\n",
       "      <td>0.691293</td>\n",
       "      <td>ft_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kind/test-flake</td>\n",
       "      <td>2170</td>\n",
       "      <td>0.912442</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kind/test-flake</td>\n",
       "      <td>2170</td>\n",
       "      <td>0.930876</td>\n",
       "      <td>0.922374</td>\n",
       "      <td>0.939535</td>\n",
       "      <td>ft_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component/cli</td>\n",
       "      <td>1746</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.737968</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component/cli</td>\n",
       "      <td>1746</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>ft_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kind/question</td>\n",
       "      <td>1496</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.760736</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kind/question</td>\n",
       "      <td>1496</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>ft_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kind/feature</td>\n",
       "      <td>110</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>ft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kind/feature</td>\n",
       "      <td>110</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>ft_pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label     n  accuracy  precision    recall  model\n",
       "0         kind/bug  3736  0.700535   0.713528  0.698701     ft\n",
       "1         kind/bug  3736  0.675134   0.675258  0.691293  ft_pt\n",
       "2  kind/test-flake  2170  0.912442   0.910891  0.901961     ft\n",
       "3  kind/test-flake  2170  0.930876   0.922374  0.939535  ft_pt\n",
       "4    component/cli  1746  0.780000   0.737968  0.831325     ft\n",
       "5    component/cli  1746  0.782857   0.737864  0.873563  ft_pt\n",
       "6    kind/question  1496  0.753333   0.760736  0.779874     ft\n",
       "7    kind/question  1496  0.770000   0.750000  0.776224  ft_pt\n",
       "8     kind/feature   110  0.727273   1.000000  0.400000     ft\n",
       "9     kind/feature   110  0.727273   0.833333  0.714286  ft_pt"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat(predicted_labels).sort_values(\"n\", ascending=False).reset_index(drop = True)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
